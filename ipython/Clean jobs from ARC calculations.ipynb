{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean jobs from ARC calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is aimed to clean up ARC calculations.\n",
    "1. migrate all calculations to `species_path` \n",
    "2. create arkane `species.py` file for thermo jobs (with UseBAC) and kinetics jobs (without BAC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "from easy_rmg_model.species.info import (classify_jobs,\n",
    "                                   find_latest_terminated_job,\n",
    "                                   check_converge_and_geom_consist,\n",
    "                                   generate_geom_info,\n",
    "                                   find_rotors_from_xyz,\n",
    "                                   filter_scans,\n",
    "                                   check_scan_quality,\n",
    "                                   generate_summary,)\n",
    "\n",
    "\n",
    "from easy_rmg_model.template_writer.input import ArkaneSpecies, ArkaneThermo\n",
    "\n",
    "import subprocess\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_data(spc, save_dir='', output_file_name='output.out'):\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    for job_type in ['composite', 'sp', 'freq',]:\n",
    "        try:\n",
    "            path = spc[job_type]\n",
    "            save_at = os.path.join(save_dir, job_type)\n",
    "            os.makedirs(save_at, exist_ok=True)\n",
    "            shutil.copy(path, os.path.join(save_at, output_file_name))\n",
    "            spc[job_type] = os.path.join(save_at, output_file_name)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    try:\n",
    "        rotors_dict = spc['rotors_dict']\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    for _, rotor in rotors_dict.items():\n",
    "        job_type = 'scan_' + '_'.join([str(i) for i in rotor['scan']])\n",
    "        save_at = os.path.join(save_dir, job_type)\n",
    "        os.makedirs(save_at, exist_ok=True)\n",
    "        if rotor['scan_path']:\n",
    "            shutil.copy(rotor['scan_path'],\n",
    "                        os.path.join(save_at,\n",
    "                                     output_file_name))\n",
    "\n",
    "            rotor['scan_path'] = os.path.join(save_at, output_file_name)\n",
    "\n",
    "\n",
    "def change_to_relative_path(spc, curdir='.'):\n",
    "    os.chdir(curdir)\n",
    "    for job_type in ['composite', 'sp', 'freq']:\n",
    "        try:\n",
    "            path = spc[job_type]\n",
    "            spc[job_type] = os.path.relpath(path)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    try:\n",
    "        rotors_dict = spc['rotors_dict']\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    for _, rotor in rotors_dict.items():\n",
    "        if rotor['scan_path']:\n",
    "            path = rotor['scan_path']\n",
    "            rotor['scan_path'] = os.path.relpath(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- all species jobs will be moved to `species_path`\n",
    "- arkane without BAC will be saved to `arkane_paths[0]`\n",
    "- arkane with BAC will be saved to `arkane_paths[1]`\n",
    "- jobs do not satisfy the criteria will be saved to `bad_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE_NAME = 'output.out'  # output file name of (gaussian) jobs\n",
    "\n",
    "LEVEL = {'composite': 'cbs-qb3',\n",
    "         'freq': 'b3lyp/cbsb7',\n",
    "         'scan': 'b3lyp/cbsb7'}\n",
    "\n",
    "SCAN_FILTER = 'non-frozen'\n",
    "# This filter make sure use the scan with fewest constraint\n",
    "# But no guarantee on the shape of the curve (less important)\n",
    "FREQ_SCALE_FACTOR = None\n",
    "\n",
    "ARKANE_SPEC = {\n",
    "    'model_chemistry': 'cbs-qb3',\n",
    "}\n",
    "\n",
    "species_path = '/Volumes/Extreme SSD/relax-rotor/Species'\n",
    "arkane_paths = ['/Volumes/Extreme SSD/relax-rotor/Arkane_Species_wo_bac',\n",
    "                '/Volumes/Extreme SSD/relax-rotor/Arkane_Species',\n",
    "               ]\n",
    "bad_path = '/Volumes/Extreme SSD/relax-rotor/NeedImprove/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Migrate jobs and create arkane input/species files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`work_path` is usually the path to `ARC_PROJECT/calcs/Species/`. It also works if your jobs are organized by \n",
    "```\n",
    "- many species folders\n",
    "  |\n",
    "  |- job folders(named by optxxx, compositexxx, freqxxx, scanxxx)\n",
    "      |\n",
    "      |- output files(e.g., output.out)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = '/Volumes/Extreme SSD/Calcs/todo/Species'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 integrated workflow\n",
    "\n",
    "An iterative and iteractive process to add calculation results to a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "smiles_list = []\n",
    "calculated_spc = [smi for smi in os.listdir(species_path) if os.path.isdir(os.path.join(species_path, smi))]\n",
    "for dir_name in os.listdir(work_path):\n",
    "\n",
    "    # Step 1. Read the path\n",
    "    job_path = os.path.join(work_path, dir_name)\n",
    "    if not os.path.isdir(job_path):\n",
    "        continue\n",
    "    print('\\n', job_path)\n",
    "\n",
    "    # Step 2. Initiate a `spc` dict to store species information\n",
    "    spc = {'label': 'species',\n",
    "           'directory': os.path.join(work_path, dir_name),\n",
    "           'ts': False}\n",
    "\n",
    "    # Step 3. Go through each steps to check the calculation quality\n",
    "    try:\n",
    "        classify_jobs(spc)\n",
    "        find_latest_terminated_job(spc)\n",
    "        check_converge_and_geom_consist(spc)\n",
    "        generate_geom_info(spc)\n",
    "        find_rotors_from_xyz(spc)\n",
    "        filter_scans(spc, scan_filter='')\n",
    "        check_scan_quality(spc)\n",
    "    except (KeyError, FileNotFoundError) as e:\n",
    "        print(dir_name)\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "    print(generate_summary(spc))\n",
    "    if spc['smiles'] in calculated_spc:\n",
    "        print(f\"{spc['smiles']} is in the folder, skip\")\n",
    "    else:\n",
    "        print(f\"{spc['smiles']} is new\")\n",
    "\n",
    "\n",
    "    keep = None\n",
    "    while keep not in ['Y', 'N', 'y', 'n', 'yes', 'no']:\n",
    "        keep = input('Whether to keep this job (Y/N)?: ')\n",
    "\n",
    "    if keep in  ['Y', 'y', 'yes',]:\n",
    "        migrate = None\n",
    "        while migrate not in ['Y', 'N', 'y', 'n', 'yes', 'no']:\n",
    "            migrate = input('Whether to migrate this job (Y/N)?: ')\n",
    "        if migrate in ['Y', 'y', 'yes',]:\n",
    "            # Step 5. Migrate good jobs to `species_path`\n",
    "            try:\n",
    "                transfer_data(spc, save_dir=os.path.join(species_path,\n",
    "                                                     spc['smiles']))\n",
    "                with open(os.path.join(species_path,spc['smiles'], 'summary.txt'), 'w') as f:\n",
    "                    f.write(spc['summary'])\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "\n",
    "            # Step 6. Create files for arkane jobs\n",
    "            for ind, arkane_path in enumerate(arkane_paths):\n",
    "                save_dir = os.path.join(arkane_path, spc['smiles'])\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "                change_to_relative_path(spc, save_dir)\n",
    "\n",
    "                arkane_species_path = os.path.join(save_dir, 'species.py')\n",
    "                arkane_thermo_input_path = os.path.join(save_dir, 'input.py')\n",
    "                settings = {'use_bond_corrections': bool(ind),\n",
    "                           'save_path': arkane_species_path}\n",
    "                ArkaneSpecies({**spc, **ARKANE_SPEC, **settings}).save()\n",
    "                settings = {\n",
    "                    'use_bond_corrections': bool(ind),\n",
    "                    'use_hindered_rotors': True,\n",
    "                    'species_file': os.path.relpath(arkane_species_path),\n",
    "                    'species_smiles': spc['smiles'],\n",
    "                    'save_path': arkane_thermo_input_path,\n",
    "                }\n",
    "                ArkaneThermo({**spc, **ARKANE_SPEC, **settings}).save()\n",
    "\n",
    "            smiles_list.append(spc['smiles'])\n",
    "            shutil.rmtree(job_path)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        shutil.rmtree(job_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Species in `smiles_list` will be further processed. You can manually remove some some species if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: Assign a new `smiles_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smiles_list = [\n",
    "# '[CH2]C(=C)C(C)=O'\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: Remove misjudged species from `smiles_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in [\"[CH2]C_=C_C_OO_OC_C_=O_54177_\",]:\n",
    "#     try:\n",
    "#         smiles_list.remove(i)\n",
    "#         for j in [species_path] + arkane_paths:\n",
    "#             shutil.rmtree(os.path.join(j, i))\n",
    "#     except ValueError:\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Stepwise workflow\n",
    "This is used to get familiar with the workflow, in case you do not trust the integrated workflow. This can be also used to tackle calculations that needs special cares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1. Initiate a `spc` dict to store species information\n",
    "- `label` can be anything. It won't influence the result\n",
    "- `directory` where you jobs are located\n",
    "- `ts` whether it is a TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spc = {'label': 'A',\n",
    "       'directory': '/Volumes/Extreme SSD/Calcs/todo/Species/S_2708_',\n",
    "       'ts': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Go through each steps to check the calculation quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_spc = [smi for smi in os.listdir(species_path) if os.path.isdir(os.path.join(species_path, smi))]\n",
    "\n",
    "classify_jobs(spc)\n",
    "find_latest_terminated_job(spc)\n",
    "check_converge_and_geom_consist(spc)\n",
    "generate_geom_info(spc)\n",
    "find_rotors_from_xyz(spc)\n",
    "filter_scans(spc, scan_filter='')\n",
    "check_scan_quality(spc)\n",
    "\n",
    "if spc['smiles'] in calculated_spc:\n",
    "    print(f\"{spc['smiles']} is in the folder, skip\")\n",
    "else:\n",
    "    print(f\"{spc['smiles']} is new\")\n",
    "    print(generate_summary(spc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases, the generated `rotor_dicts` is not desirable. You may have to manually modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the entry of a `rotors_dict` (a list)\n",
    "# i = 1\n",
    "# spc['rotors_dict'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spc['rotors_dict'][i]['scan'] = []  # INPUT!! A index-1 list\n",
    "# spc['rotors_dict'][i]['top'] = []  # INPUT!!\n",
    "# spc['rotors_dict'][i]['success'] = True  # INPUT!!\n",
    "# spc['rotors_dict'][i]['symmetry'] = 1  # INPUT!!\n",
    "\n",
    "\n",
    "# spc['rotors_dict'][i]['pivots'] = spc['rotors_dict'][i]['scan'][1:3]\n",
    "# spc['rotors_dict'][i]['torsion'] = [t-1 for t in spc['rotors_dict'][i]['scan']]\n",
    "# generate_summary(spc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Step 3. If any step does not meet the criteria, then move it to `bad_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_data(spc, save_dir=os.path.join(bad_path,\n",
    "#                                          spc['smiles']))\n",
    "# with open(os.path.join(bad_path, spc['smiles'], 'summary.txt'), 'w') as f:\n",
    "#     f.write(spc['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Migrate good jobs to `species_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_data(spc, save_dir=os.path.join(species_path,\n",
    "                                         spc['smiles']))\n",
    "with open(os.path.join(species_path, spc['smiles'], 'summary.txt'), 'w') as f:\n",
    "    f.write(spc['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5. Create files for arkane jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, arkane_path in enumerate(arkane_paths):\n",
    "    save_dir = os.path.join(arkane_path, spc['smiles'])\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    change_to_relative_path(spc, save_dir)\n",
    "\n",
    "    arkane_species_path = os.path.join(save_dir, 'species.py')\n",
    "    arkane_thermo_input_path = os.path.join(save_dir, 'input.py')\n",
    "    settings = {'use_bond_corrections': bool(ind),\n",
    "               'save_path': arkane_species_path}\n",
    "    ArkaneSpecies({**spc, **ARKANE_SPEC, **settings}).save()\n",
    "    settings = {\n",
    "        'use_bond_corrections': bool(ind),\n",
    "        'use_hindered_rotors': True,\n",
    "        'species_file': os.path.relpath(arkane_species_path),\n",
    "        'species_smiles': spc['smiles'],\n",
    "        'save_path': arkane_thermo_input_path,\n",
    "    }\n",
    "    ArkaneThermo({**spc, **ARKANE_SPEC, **settings}).save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check the Arkane files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.EnumerateStereoisomers import EnumerateStereoisomers, StereoEnumerationOptions, GetStereoisomerCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arkane_paths = ['/Volumes/Extreme SSD/relax-rotor/Arkane_Species_wo_bac',\n",
    "                '/Volumes/Extreme SSD/relax-rotor/Arkane_Species',\n",
    "               ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Correct the stereoIsomers number\n",
    "- ARC may underestimate the number if multiple stereocenters exist\n",
    "- ARC may overestimate the number if the molecule has no chiral center but the conformer has distingushiable mirror image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for subpath in smiles_list:\n",
    "    mol = Chem.MolFromSmiles(subpath)\n",
    "    if mol:\n",
    "        # Find chiral centers (chiral carbons, does not include Z/E for C=C)\n",
    "        chiral = Chem.FindMolChiralCenters(mol, force=True, includeUnassigned=True)\n",
    "    else:\n",
    "        # Smiles cannot be read, a\n",
    "        continue\n",
    "\n",
    "    # Get the \n",
    "    if chiral:\n",
    "        # Try to get number of stereoisomers (Currently include Z/E for C=C)\n",
    "        try:\n",
    "            opts = StereoEnumerationOptions(tryEmbedding=True, unique=True)\n",
    "            isomers = EnumerateStereoisomers(mol, opts)\n",
    "        except:\n",
    "            ## Todo: embed may not work for TSs\n",
    "            print(f'Warning: {sub_path} needs manual check')\n",
    "        else:\n",
    "            num_chiral = len([isomer for isomer in isomers])\n",
    "            if num_chiral < 1:\n",
    "                print(f'Warning: {sub_path} needs manual check')\n",
    "    else:\n",
    "        num_chiral = 1\n",
    "\n",
    "    # Open the Arkane species file\n",
    "    try:\n",
    "        with open(os.path.join(arkane_paths[1], subpath, 'species.py')) as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f'Cannot find: {subpath}')\n",
    "        continue\n",
    "\n",
    "    # Check whether opticalIsomers in the file is not consistent with the number from RDKit\n",
    "    flag = True\n",
    "    with open(os.path.join(arkane_paths[1], subpath, 'speceis.py.backup'), 'w') as f:\n",
    "        for line in lines:\n",
    "            if 'opticalIsomers' in line:\n",
    "                rmg_num = int(line.strip().split()[2])\n",
    "                if rmg_num != num_chiral:\n",
    "                    print(subpath)\n",
    "                    print('chiral center:', chiral)\n",
    "                    print('rdkit:',num_chiral,'  species_file:',rmg_num)\n",
    "                    \n",
    "                    line = ' '. join(line.strip().split()[0:2])\n",
    "                    line += f' {num_chiral}\\n'\n",
    "                    flag = False\n",
    "            f.write(line)\n",
    "    \n",
    "    # Correct the opticalIsomers number if necessary\n",
    "    if not flag:\n",
    "        shutil.copy(os.path.join(arkane_paths[1], subpath, 'speceis.py.backup'),\n",
    "                    os.path.join(arkane_paths[1], subpath, 'species.py'))          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Correct the symmetry number of rotors\n",
    "- ARC cannot predict the symmetry if the curves are bad looking (can be numbers 0 to 6). Simply assign 1 to those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Naive way\n",
    "Make those `symmetry` < 0 or > 3 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subpath in smiles_list:\n",
    "    try:\n",
    "        with open(os.path.join(arkane_paths[1], subpath, 'species.py')) as f:\n",
    "            lines = f.readlines()\n",
    "    except (FileNotFoundError, NotADirectoryError):\n",
    "        print(subpath)\n",
    "        continue\n",
    "        \n",
    "    with open(os.path.join(arkane_paths[1], subpath, 'speceis.py.backup'), 'w') as f:\n",
    "        for line in lines:\n",
    "            if 'symmetry=' in line:\n",
    "                rmg_num = int(line.strip().split('=')[1].split(',')[0])\n",
    "                if rmg_num > 3 or rmg_num <= 0:\n",
    "                    line = line.replace(str(rmg_num), str(1))\n",
    "                    print(subpath)\n",
    "                    print(rmg_num)\n",
    "            f.write(line)\n",
    "    shutil.copy(os.path.join(arkane_paths[1], subpath, 'speceis.py.backup'),\n",
    "                os.path.join(arkane_paths[1], subpath, 'species.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Check the curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arc.parser import parse_1d_scan_energies\n",
    "from arc.species.species import cyclic_index_i_plus_1, cyclic_index_i_minus_1, determine_rotor_symmetry\n",
    "from arc.plotter import plot_1d_rotor_scan\n",
    "\n",
    "def determine_rotor_sym(rotor_path):\n",
    "    energies = parse_1d_scan_energies(path=rotor_path)[0]\n",
    "    max_e = max(energies)\n",
    "    tol = 0.1 * max_e if max_e > 2000 else max_e\n",
    "    min_e = min(energies)\n",
    "    peaks, valleys = list(), list()  # the peaks and valleys of the scan\n",
    "    worst_peak_resolution, worst_valley_resolution = 0, 0\n",
    "    for i, e in enumerate(energies):\n",
    "        # identify peaks and valleys, and determine worst resolutions in the scan\n",
    "        ip1 = cyclic_index_i_plus_1(i, len(energies))  # i Plus 1\n",
    "        im1 = cyclic_index_i_minus_1(i)                # i Minus 1\n",
    "        if i == 0 and energies[im1] == e:\n",
    "            # If the first and last scan points have same energy, change im1\n",
    "            im1 -= 1\n",
    "        if e > energies[im1] and e > energies[ip1]:\n",
    "            # this is a local peak\n",
    "            if any([diff > worst_peak_resolution for diff in [e - energies[im1], e - energies[ip1]]]):\n",
    "                worst_peak_resolution = max(e - energies[im1], e - energies[ip1])\n",
    "            peaks.append(e)\n",
    "        elif e < energies[im1] and e < energies[ip1]:\n",
    "            # this is a local valley\n",
    "            if any([diff > worst_valley_resolution for diff in [energies[im1] - e, energies[ip1] - e]]):\n",
    "                worst_valley_resolution = max(energies[im1] - e, energies[ip1] - e)\n",
    "            valleys.append(e)\n",
    "\n",
    "    if len(peaks) != len(valleys):\n",
    "        symmetry = 1\n",
    "    else:\n",
    "        symmetry = determine_rotor_symmetry('species', [0, 0], energies=energies, log=False)[0]\n",
    "    return symmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subpath in os.listdir(arkane_paths[1]):\n",
    "for subpath in smiles_list:\n",
    "    try:\n",
    "        with open(os.path.join(arkane_paths[1], subpath, 'species.py')) as f:\n",
    "            lines = f.readlines()\n",
    "    except (FileNotFoundError, NotADirectoryError):\n",
    "        print(subpath)\n",
    "        continue\n",
    "    \n",
    "    os.chdir(os.path.join(arkane_paths[1], subpath,))    \n",
    "    with open(os.path.join(arkane_paths[1], subpath, 'speceis.py.backup'), 'w') as f:\n",
    "        for line in lines:\n",
    "            if 'scanLog' in line:\n",
    "                rotor_path = os.path.realpath(line.strip().split(\"'\")[1])\n",
    "                sym = determine_rotor_sym(rotor_path)\n",
    "            if 'symmetry=' in line:\n",
    "                rmg_num = int(line.strip().split('=')[1].split(',')[0])\n",
    "                if rmg_num != sym:\n",
    "                    print(subpath)\n",
    "                    print(rotor_path)\n",
    "                    print(f'Original: {rmg_num}, New: {sym}')\n",
    "                    if sym != 1:\n",
    "                        energies, angles = parse_1d_scan_energies(rotor_path)\n",
    "                        plot_1d_rotor_scan(angles, energies)\n",
    "                        sym = input('What is the symmetry?')\n",
    "                    line = line.replace(str(rmg_num), str(sym))\n",
    "                    \n",
    "            f.write(line)\n",
    "    shutil.copy(os.path.join(arkane_paths[1], subpath, 'speceis.py.backup'),\n",
    "                os.path.join(arkane_paths[1], subpath, 'species.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Update the arkane files without BAC\n",
    "Previous changes have not been applied to Arkane files without BAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for subpath in os.listdir(arkane_paths[1]):\n",
    "for subpath in smiles_list:\n",
    "    species_file = os.path.join(arkane_paths[1], subpath, 'species.py')\n",
    "    if os.path.isfile(species_file):\n",
    "        if not os.path.isdir(os.path.join(arkane_paths[0], subpath)):\n",
    "            os.makedirs(os.path.join(arkane_paths[0], subpath))\n",
    "        shutil.copy(species_file,\n",
    "                    os.path.join(arkane_paths[0], subpath, 'species.py'))\n",
    "    else:\n",
    "        print(f'Path {species_file} does not exist')\n",
    "        continue\n",
    "\n",
    "    input_file = os.path.join(arkane_paths[1], subpath, 'input.py')\n",
    "    if os.path.isfile(input_file):\n",
    "        shutil.copy(input_file,\n",
    "                    os.path.join(arkane_paths[0], subpath, 'input.py'))\n",
    "           \n",
    "    try:\n",
    "        with open(os.path.join(arkane_paths[0], subpath, 'species.py')) as f:\n",
    "            lines = f.readlines()\n",
    "    except (FileNotFoundError, NotADirectoryError):\n",
    "        print(subpath)\n",
    "        continue\n",
    "\n",
    "    with open(os.path.join(arkane_paths[0], subpath, 'species.py.backup'), 'w') as f:\n",
    "        for line in lines:\n",
    "            if 'useBondCorrections' in line:\n",
    "                line = line.replace('True', 'False')\n",
    "            f.write(line)\n",
    "\n",
    "    shutil.copy(os.path.join(arkane_paths[0], subpath, 'species.py.backup'),\n",
    "                os.path.join(arkane_paths[0], subpath, 'species.py'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Rerun Arkane jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target_species = list(os.listdir(arkane_paths[1]))\n",
    "Target_species = smiles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subpath in Target_species:\n",
    "    if os.path.isfile(os.path.join(arkane_paths[1], subpath, 'input.py')):\n",
    "        subprocess.run('python $ARKANE input.py', cwd=os.path.join(arkane_paths[1], subpath), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Remove the finished species from NeedImprove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spcs = os.listdir(species_path)\n",
    "need_improve = os.listdir(bad_path)\n",
    "for item in need_improve:\n",
    "    if item in spcs:\n",
    "        try:\n",
    "            print('deleting', item)\n",
    "            shutil.rmtree(os.path.join(bad_path, item))\n",
    "        except NotADirectoryError:\n",
    "            print(item)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "interpreter": {
   "hash": "f734dd8bb8dba54e055a6b986ac72a1a3509c3dff380149774060d53d7aed57a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('arc_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
